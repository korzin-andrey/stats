{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15600\n"
     ]
    }
   ],
   "source": [
    "def sample_size(p, rel_tol) -> int:\n",
    "    n = 0\n",
    "    error = rel_tol + 1\n",
    "    while error > rel_tol:\n",
    "        n += 1\n",
    "        sigma_phi = np.sqrt((1-p)/(n*p))\n",
    "        error = sigma_phi\n",
    "    return n\n",
    "\n",
    "\n",
    "p = 0.025\n",
    "rel_tol = 0.05\n",
    "\n",
    "n = sample_size(p, rel_tol)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4579\n"
     ]
    }
   ],
   "source": [
    "def sample_size(gamma, alpha, delta):\n",
    "    error = delta + 1\n",
    "    n = 1\n",
    "    while error >= delta:\n",
    "        z_quantile = ss.norm.ppf(1 - alpha)\n",
    "        phi_z_quantile = ss.norm.pdf(z_quantile)\n",
    "        error = (gamma/(6*np.sqrt(n)))*(2*z_quantile**2+1)*phi_z_quantile\n",
    "        n+=1\n",
    "    return n-1\n",
    "\n",
    "result = sample_size(2, 0.025, 0.025 * 0.1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доверительный интервал для p: (0.052368745896216595, 0.36041886474075696)\n"
     ]
    }
   ],
   "source": [
    "def pivot_interval(n, k, gamma):\n",
    "    sample_mean = k/n\n",
    "    z = ss.norm.ppf((1-gamma)/2)\n",
    "    a = z**2 + n\n",
    "    b = (2*n*sample_mean + z**2)\n",
    "    c = n*sample_mean**2\n",
    "    p_R = -(-b - np.sqrt(b**2-4*a*c))/(2*a)\n",
    "    p_L = -(-b + np.sqrt(b**2-4*a*c))/(2*a)\n",
    "    return p_L, p_R\n",
    "\n",
    "\n",
    "n = 20\n",
    "k = 3\n",
    "gamma = 0.95\n",
    "\n",
    "p_alpha, p_beta = pivot_interval(n, k, gamma)\n",
    "print(\"Доверительный интервал для p:\", (p_alpha, p_beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.09952454760270645, 509.12913485983375)\n"
     ]
    }
   ],
   "source": [
    "def var_interval(sample, gamma):\n",
    "    n = len(sample)\n",
    "    alpha = 1 - gamma\n",
    "    g_1 = ss.chi2.ppf(alpha / 2, n - 1)\n",
    "    g_2 = ss.chi2.ppf(1 - alpha / 2, n - 1)\n",
    "    sample_variance = np.var(sample, ddof=1)\n",
    "    lower_bound = (n - 1) * sample_variance / g_2\n",
    "    upper_bound = (n - 1) * sample_variance / g_1\n",
    "    return (lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "print(var_interval([0, 1], 0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.6050185968267746, 0.15172480236498656)\n"
     ]
    }
   ],
   "source": [
    "def loc_interval(sample, gamma, number_of_trials):\n",
    "    # MONTE-CARLO for quantiles\n",
    "    n = len(sample)\n",
    "    loc = 1\n",
    "    scale = 5\n",
    "    sample_monte_carlo = ss.cauchy(loc=loc, scale=scale).rvs((number_of_trials, n))\n",
    "    med = np.median(sample_monte_carlo, axis=1)\n",
    "    MAD = np.median(abs(sample_monte_carlo - np.resize(med, (number_of_trials, n))), axis=1)\n",
    "    g = (med - loc)/MAD\n",
    "    alpha = 1 - gamma\n",
    "    quantile_1 = np.quantile(g, alpha/2)\n",
    "    quantile_2 = np.quantile(g, 1 - alpha/2)\n",
    "    # CONFIDENCE INTERVAL\n",
    "    med_loc = np.median(sample)\n",
    "    MAD_loc = np.median(abs(sample - np.resize(med_loc, (1, n))))\n",
    "    loc_2 = med_loc - MAD_loc*quantile_1\n",
    "    loc_1 = med_loc - MAD_loc*quantile_2\n",
    "    return loc_1, loc_2\n",
    "\n",
    "\n",
    "sample = [-0.93, -1.84, -0.84, -0.13, -0.63, 0.06, -0.93, 13.29, 0.9, -2.64,\n",
    "          -0.37, 0.43, -2.41, 19.33, -0.18, 1.29, 1.32, -0.47, -0.27, 0.27,\n",
    "          1.07, -1.49, -0.78, 0.59, -0.0, -1.59, -0.28, -1.38, 0.1, 1.72]\n",
    "print(loc_interval(sample, 0.95, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'c_d_mean' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[228], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     ratio \u001b[38;5;241m=\u001b[39m sigma\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m c_d_mean\u001b[38;5;241m/\u001b[39mc_d_med\n\u001b[0;32m---> 26\u001b[0m \u001b[43mratio\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# from scipy.optimize import root_scalar\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# print(root_scalar(lambda x: ratio(x) - 1, bracket=[0, 0.5]).root)\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[228], line 24\u001b[0m, in \u001b[0;36mratio\u001b[0;34m(eps)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# sigma = np.sqrt((1-eps)*sigma_1**2 + eps*sigma_2**2)\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# sample = mixture(10000, eps)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m ratio \u001b[38;5;241m=\u001b[39m sigma\n\u001b[0;32m---> 24\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mc_d_mean\u001b[49m\u001b[38;5;241m/\u001b[39mc_d_med\n",
      "\u001b[0;31mNameError\u001b[0m: name 'c_d_mean' is not defined"
     ]
    }
   ],
   "source": [
    "def mixture(n, eps):\n",
    "# Задаем параметры компонентов смеси\n",
    "    mu1, sigma1 = 0, 1\n",
    "    mu2, sigma2 = 0, 5\n",
    "\n",
    "    # Генерируем выборку смешанной смеси\n",
    "    component_choice = np.random.choice([0, 1], size=n, p=[1-eps, eps])\n",
    "    sample = np.empty(n)\n",
    "    for i, component in enumerate(component_choice):\n",
    "        if component == 0:\n",
    "            sample[i] = np.random.normal(mu1, sigma1)\n",
    "        else:\n",
    "            sample[i] = np.random.normal(mu2, sigma2)\n",
    "    \n",
    "    return sample\n",
    "\n",
    "def ratio(eps):\n",
    "    sigma_1 = 1\n",
    "    sigma_2 = 5\n",
    "    sigma = np.sqrt(1-(4/5)*eps)\n",
    "    # sigma = np.sqrt((1-eps)*sigma_1**2 + eps*sigma_2**2)\n",
    "    # sample = mixture(10000, eps)\n",
    "    ratio = sigma\n",
    "    return c_d_mean/c_d_med\n",
    "\n",
    "ratio(0)\n",
    "\n",
    "# from scipy.optimize import root_scalar\n",
    "# print(root_scalar(lambda x: ratio(x) - 1, bracket=[0, 0.5]).root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4854712460301556, 0.9124958350575495]\n"
     ]
    }
   ],
   "source": [
    "def corr_interval(sample, gamma):\n",
    "    n = len(sample)\n",
    "    x, y = zip(*sample)\n",
    "    rho = np.corrcoef(x, y)[1, 0]\n",
    "    z_conf = ss.norm.ppf(1 - (1 - gamma) / 2)\n",
    "    ci_left = np.tanh(np.arctanh(rho) - z_conf/np.sqrt(n))\n",
    "    ci_right = np.tanh(np.arctanh(rho) + z_conf/np.sqrt(n))\n",
    "    return [ci_left, ci_right]\n",
    "\n",
    "\n",
    "data = np.array([(576, 3.39), (635, 3.30), (558, 2.81), (578, 3.03), (666, 3.44),\n",
    "                 (580, 3.07), (555, 3.0), (661, 3.43), (651, 3.36), (605, 3.13),\n",
    "                 (653, 3.12), (575, 2.74), (545, 2.76), (572, 2.88), (594, 2.96)])\n",
    "\n",
    "print(corr_interval(data, 0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1034, 0.0775)\n"
     ]
    }
   ],
   "source": [
    "# def corr_coeff(sample):\n",
    "#     corr_coeff_arr = []\n",
    "#     for i in range(len(sample)):\n",
    "#         x, y = zip(*sample[i])\n",
    "#         corr_coeff_arr.append(np.corrcoef(x,y)[0,1])\n",
    "#     return corr_coeff_arr\n",
    "\n",
    "def corr_interval(sample, gamma):\n",
    "    n = len(sample)\n",
    "    x, y = zip(*sample)\n",
    "    rho = np.corrcoef(x, y)[1, 0]\n",
    "    z_conf = ss.norm.ppf(1 - (1 - gamma) / 2)\n",
    "    ci_left = np.tanh(np.arctanh(rho) - z_conf/np.sqrt(n))\n",
    "    ci_right = np.tanh(np.arctanh(rho) + z_conf/np.sqrt(n))\n",
    "    return [ci_left, ci_right]\n",
    "\n",
    "def true_proba(n, rho, gamma, number_of_trials):\n",
    "    alpha = np.sqrt(rho / (1 - rho))\n",
    "    z = ss.expon.rvs(size=(number_of_trials, n))\n",
    "    x = ss.expon.rvs(size=(number_of_trials, n)) + alpha * z\n",
    "    y = ss.expon.rvs(size=(number_of_trials, n)) + alpha * z\n",
    "    samples = np.stack([x, y], axis=-1)\n",
    "    corr_interval_arr = [corr_interval(sample, gamma) for sample in samples]\n",
    "    left, right = zip(*corr_interval_arr)\n",
    "    left = np.array(left)\n",
    "    right = np.array(right)\n",
    "    prob_left = np.sum(rho > right)/number_of_trials\n",
    "    prob_right = np.sum(rho < left)/number_of_trials\n",
    "    return prob_right, prob_left\n",
    "\n",
    "print(true_proba(30, 0.6, 0.95, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "a must be 1-dimensional",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[278], line 46\u001b[0m\n\u001b[1;32m     43\u001b[0m number_of_trials \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000\u001b[39m\n\u001b[1;32m     44\u001b[0m n_of_resamples \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n\u001b[0;32m---> 46\u001b[0m proba_left, proba_right \u001b[38;5;241m=\u001b[39m \u001b[43mefron_true_proba\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m    \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_trials\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_of_resamples\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mВероятность, что rho < lower_bound:\u001b[39m\u001b[38;5;124m\"\u001b[39m, proba_left)\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mВероятность, что rho > upper_bound:\u001b[39m\u001b[38;5;124m\"\u001b[39m, proba_right)\n",
      "Cell \u001b[0;32mIn[278], line 15\u001b[0m, in \u001b[0;36mefron_true_proba\u001b[0;34m(n, rho, gamma, number_of_trials, n_of_resamples)\u001b[0m\n\u001b[1;32m     12\u001b[0m left_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_trials):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Бутстрапирование\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     resamples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43m[\u001b[49m\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m                         \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mrange\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mn_of_resamples\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Оценка корреляций\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     correlations \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mcorrcoef(resample[:, \u001b[38;5;241m0\u001b[39m], resample[:, \u001b[38;5;241m1\u001b[39m])[\n\u001b[1;32m     20\u001b[0m                             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m resample \u001b[38;5;129;01min\u001b[39;00m resamples])\n",
      "Cell \u001b[0;32mIn[278], line 15\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     12\u001b[0m left_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(number_of_trials):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# Бутстрапирование\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     resamples \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchoice\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m                          \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_of_resamples)])\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;66;03m# Оценка корреляций\u001b[39;00m\n\u001b[1;32m     19\u001b[0m     correlations \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([np\u001b[38;5;241m.\u001b[39mcorrcoef(resample[:, \u001b[38;5;241m0\u001b[39m], resample[:, \u001b[38;5;241m1\u001b[39m])[\n\u001b[1;32m     20\u001b[0m                             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m resample \u001b[38;5;129;01min\u001b[39;00m resamples])\n",
      "File \u001b[0;32mnumpy/random/mtrand.pyx:947\u001b[0m, in \u001b[0;36mnumpy.random.mtrand.RandomState.choice\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: a must be 1-dimensional"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def efron_true_proba(n, rho, gamma, number_of_trials, n_of_resamples):\n",
    "    alpha = np.sqrt(rho / (1 - rho))\n",
    "    z = ss.expon.rvs(size=(number_of_trials, n))\n",
    "    x = ss.expon.rvs(size=(number_of_trials, n)) + alpha * z\n",
    "    y = ss.expon.rvs(size=(number_of_trials, n)) + alpha * z\n",
    "    samples = np.stack([x, y], axis=-1)\n",
    "    \n",
    "    return efron_left, efron_right\n",
    "\n",
    "\n",
    "print(efron_true_proba(30, 0.6, 0.95, 10000, 1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
