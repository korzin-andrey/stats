{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15600\n"
     ]
    }
   ],
   "source": [
    "def sample_size(p, rel_tol) -> int:\n",
    "    n = 0\n",
    "    error = rel_tol + 1\n",
    "    while error > rel_tol:\n",
    "        n += 1\n",
    "        sigma_phi = np.sqrt((1-p)/(n*p))\n",
    "        error = sigma_phi\n",
    "    return n\n",
    "\n",
    "\n",
    "p = 0.025\n",
    "rel_tol = 0.05\n",
    "\n",
    "n = sample_size(p, rel_tol)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4579\n"
     ]
    }
   ],
   "source": [
    "def sample_size(gamma, alpha, delta):\n",
    "    error = delta + 1\n",
    "    n = 1\n",
    "    while error >= delta:\n",
    "        z_quantile = ss.norm.ppf(1 - alpha)\n",
    "        phi_z_quantile = ss.norm.pdf(z_quantile)\n",
    "        error = (gamma/(6*np.sqrt(n)))*(2*z_quantile**2+1)*phi_z_quantile\n",
    "        n+=1\n",
    "    return n-1\n",
    "\n",
    "result = sample_size(2, 0.025, 0.025 * 0.1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доверительный интервал для p: (0.052368745896216595, 0.36041886474075696)\n"
     ]
    }
   ],
   "source": [
    "def pivot_interval(n, k, gamma):\n",
    "    sample_mean = k/n\n",
    "    z = ss.norm.ppf((1-gamma)/2)\n",
    "    a = z**2 + n\n",
    "    b = (2*n*sample_mean + z**2)\n",
    "    c = n*sample_mean**2\n",
    "    p_R = -(-b - np.sqrt(b**2-4*a*c))/(2*a)\n",
    "    p_L = -(-b + np.sqrt(b**2-4*a*c))/(2*a)\n",
    "    return p_L, p_R\n",
    "\n",
    "\n",
    "n = 20\n",
    "k = 3\n",
    "gamma = 0.95\n",
    "\n",
    "p_alpha, p_beta = pivot_interval(n, k, gamma)\n",
    "print(\"Доверительный интервал для p:\", (p_alpha, p_beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.09952454760270645, 509.12913485983375)\n"
     ]
    }
   ],
   "source": [
    "def var_interval(sample, gamma):\n",
    "    n = len(sample)\n",
    "    alpha = 1 - gamma\n",
    "    g_1 = ss.chi2.ppf(alpha / 2, n - 1)\n",
    "    g_2 = ss.chi2.ppf(1 - alpha / 2, n - 1)\n",
    "    sample_variance = np.var(sample, ddof=1)\n",
    "    lower_bound = (n - 1) * sample_variance / g_2\n",
    "    upper_bound = (n - 1) * sample_variance / g_1\n",
    "    return (lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "print(var_interval([0, 1], 0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.6044365545271958, 0.16065599615307222)\n"
     ]
    }
   ],
   "source": [
    "def loc_interval(sample, gamma, number_of_trials):\n",
    "    # MONTE-CARLO for quantiles\n",
    "    n = len(sample)\n",
    "    loc = 1\n",
    "    scale = 5\n",
    "    sample_monte_carlo = ss.cauchy(loc=loc, scale=scale).rvs((number_of_trials, n))\n",
    "    med = np.median(sample_monte_carlo, axis=1)\n",
    "    MAD = np.median(abs(sample_monte_carlo - np.resize(med, (number_of_trials, n))), axis=1)\n",
    "    g = (med - loc)/MAD\n",
    "    alpha = 1 - gamma\n",
    "    quantile_1 = np.quantile(g, alpha/2)\n",
    "    quantile_2 = np.quantile(g, 1 - alpha/2)\n",
    "    # CONFIDENCE INTERVAL\n",
    "    med_loc = np.median(sample)\n",
    "    MAD_loc = np.median(abs(sample - np.resize(med_loc, (1, n))))\n",
    "    loc_2 = med_loc - MAD_loc*quantile_1\n",
    "    loc_1 = med_loc - MAD_loc*quantile_2\n",
    "    return loc_1, loc_2\n",
    "\n",
    "\n",
    "sample = [-0.93, -1.84, -0.84, -0.13, -0.63, 0.06, -0.93, 13.29, 0.9, -2.64,\n",
    "          -0.37, 0.43, -2.41, 19.33, -0.18, 1.29, 1.32, -0.47, -0.27, 0.27,\n",
    "          1.07, -1.49, -0.78, 0.59, -0.0, -1.59, -0.28, -1.38, 0.1, 1.72]\n",
    "print(loc_interval(sample, 0.95, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026667806686548504\n",
      "0.6366197723675814\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import root_scalar\n",
    "def ratio(eps):\n",
    "    sigma_1 = 1\n",
    "    sigma_2 = 5\n",
    "    sigma_mean = (1-eps)*sigma_1**2 + eps*sigma_2**2\n",
    "    alpha = 0.5\n",
    "    x_alpha = 0\n",
    "    mixture_pdf = (1-eps)*(1/sigma_1/np.sqrt(2*np.pi))*np.exp(-x_alpha**2/2/sigma_1**2) + \\\n",
    "        eps*(1/sigma_2/np.sqrt(2*np.pi))*np.exp(-x_alpha**2/2/sigma_2**2)\n",
    "    sigma_median = alpha*(1-alpha)/mixture_pdf**2\n",
    "    ratio = sigma_mean/sigma_median\n",
    "    return ratio\n",
    "\n",
    "\n",
    "print(root_scalar(lambda x: ratio(x) - 1, bracket=[0, 0.5]).root)\n",
    "eps = 0\n",
    "print(ratio(eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4854712460301556, 0.9124958350575495]\n"
     ]
    }
   ],
   "source": [
    "def corr_interval(sample, gamma):\n",
    "    n = len(sample)\n",
    "    x, y = zip(*sample)\n",
    "    rho = np.corrcoef(x, y)[1, 0]\n",
    "    z_conf = ss.norm.ppf(1 - (1 - gamma) / 2)\n",
    "    ci_left = np.tanh(np.arctanh(rho) - z_conf/np.sqrt(n))\n",
    "    ci_right = np.tanh(np.arctanh(rho) + z_conf/np.sqrt(n))\n",
    "    return [ci_left, ci_right]\n",
    "\n",
    "\n",
    "data = np.array([(576, 3.39), (635, 3.30), (558, 2.81), (578, 3.03), (666, 3.44),\n",
    "                 (580, 3.07), (555, 3.0), (661, 3.43), (651, 3.36), (605, 3.13),\n",
    "                 (653, 3.12), (575, 2.74), (545, 2.76), (572, 2.88), (594, 2.96)])\n",
    "\n",
    "print(corr_interval(data, 0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1023, 0.0757)\n"
     ]
    }
   ],
   "source": [
    "def corr_interval(sample, gamma):\n",
    "    n = len(sample)\n",
    "    x, y = zip(*sample)\n",
    "    rho = np.corrcoef(x, y)[1, 0]\n",
    "    z_conf = ss.norm.ppf(1 - (1 - gamma) / 2)\n",
    "    ci_left = np.tanh(np.arctanh(rho) - z_conf/np.sqrt(n))\n",
    "    ci_right = np.tanh(np.arctanh(rho) + z_conf/np.sqrt(n))\n",
    "    return [ci_left, ci_right]\n",
    "\n",
    "def true_proba(n, rho, gamma, number_of_trials):\n",
    "    alpha = np.sqrt(rho / (1 - rho))\n",
    "    z = ss.expon.rvs(size=(number_of_trials, n))\n",
    "    x = ss.expon.rvs(size=(number_of_trials, n)) + alpha * z\n",
    "    y = ss.expon.rvs(size=(number_of_trials, n)) + alpha * z\n",
    "    samples = np.stack([x, y], axis=-1)\n",
    "    corr_interval_arr = [corr_interval(sample, gamma) for sample in samples]\n",
    "    left, right = zip(*corr_interval_arr)\n",
    "    left = np.array(left)\n",
    "    right = np.array(right)\n",
    "    prob_left = np.sum(rho > right)/number_of_trials\n",
    "    prob_right = np.sum(rho < left)/number_of_trials\n",
    "    return prob_right, prob_left\n",
    "\n",
    "print(true_proba(30, 0.6, 0.95, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 1398/10000 [02:33<15:45,  9.10it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[71], line 85\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m prob_right, prob_left\n\u001b[1;32m     84\u001b[0m \u001b[38;5;66;03m# print(efron_true_proba(30, 0.6, 0.95, 100, 1000))\u001b[39;00m\n\u001b[0;32m---> 85\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mefron_true_proba_slow\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m30\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.6\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "Cell \u001b[0;32mIn[71], line 20\u001b[0m, in \u001b[0;36mefron_true_proba_slow\u001b[0;34m(n, rho, gamma, number_of_trials, n_of_resamples)\u001b[0m\n\u001b[1;32m     18\u001b[0m     bootstrap_sample \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mchoice(sample, size\u001b[38;5;241m=\u001b[39mn)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;66;03m# print(bootstrap_sample.shape)\u001b[39;00m\n\u001b[0;32m---> 20\u001b[0m     corr_coeff \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrcoef\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbootstrap_sample\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrowvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     21\u001b[0m     corr_coeff_arr\u001b[38;5;241m.\u001b[39mappend(corr_coeff)\n\u001b[1;32m     22\u001b[0m efron_borders\u001b[38;5;241m.\u001b[39mappend([np\u001b[38;5;241m.\u001b[39mquantile(corr_coeff_arr, (\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mgamma)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m),\n\u001b[1;32m     23\u001b[0m                       np\u001b[38;5;241m.\u001b[39mquantile(corr_coeff_arr, \u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39m(\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m-\u001b[39mgamma)\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m)])\n",
      "File \u001b[0;32m~/stats/.env/lib/python3.11/site-packages/numpy/lib/function_base.py:2903\u001b[0m, in \u001b[0;36mcorrcoef\u001b[0;34m(x, y, rowvar, bias, ddof, dtype)\u001b[0m\n\u001b[1;32m   2898\u001b[0m c \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m=\u001b[39m stddev[\u001b[38;5;28;01mNone\u001b[39;00m, :]\n\u001b[1;32m   2900\u001b[0m \u001b[38;5;66;03m# Clip real and imaginary parts to [-1, 1].  This does not guarantee\u001b[39;00m\n\u001b[1;32m   2901\u001b[0m \u001b[38;5;66;03m# abs(a[i,j]) <= 1 for complex arrays, but is the best we can do without\u001b[39;00m\n\u001b[1;32m   2902\u001b[0m \u001b[38;5;66;03m# excessive work.\u001b[39;00m\n\u001b[0;32m-> 2903\u001b[0m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreal\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2904\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m np\u001b[38;5;241m.\u001b[39miscomplexobj(c):\n\u001b[1;32m   2905\u001b[0m     np\u001b[38;5;241m.\u001b[39mclip(c\u001b[38;5;241m.\u001b[39mimag, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, out\u001b[38;5;241m=\u001b[39mc\u001b[38;5;241m.\u001b[39mimag)\n",
      "File \u001b[0;32m~/stats/.env/lib/python3.11/site-packages/numpy/core/fromnumeric.py:2096\u001b[0m, in \u001b[0;36m_clip_dispatcher\u001b[0;34m(a, a_min, a_max, out, **kwargs)\u001b[0m\n\u001b[1;32m   2034\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2035\u001b[0m \u001b[38;5;124;03m    Return selected slices of an array along given axis.\u001b[39;00m\n\u001b[1;32m   2036\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2091\u001b[0m \n\u001b[1;32m   2092\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m   2093\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _wrapfunc(a, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcompress\u001b[39m\u001b[38;5;124m'\u001b[39m, condition, axis\u001b[38;5;241m=\u001b[39maxis, out\u001b[38;5;241m=\u001b[39mout)\n\u001b[0;32m-> 2096\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_clip_dispatcher\u001b[39m(a, a_min, a_max, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   2097\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (a, a_min, a_max)\n\u001b[1;32m   2100\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_clip_dispatcher)\n\u001b[1;32m   2101\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclip\u001b[39m(a, a_min, a_max, out\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def efron_true_proba_slow(n, rho, gamma, number_of_trials, n_of_resamples):\n",
    "    alpha = np.sqrt(rho / (1 - rho))\n",
    "    efron_borders = []\n",
    "    rng = np.random.default_rng()\n",
    "    for i in tqdm(range(number_of_trials)):\n",
    "        z = ss.expon.rvs(size=n)\n",
    "        x = ss.expon.rvs(size=n) + alpha * z\n",
    "        y = ss.expon.rvs(size=n) + alpha * z\n",
    "        sample = np.stack([x, y], axis=-1)\n",
    "\n",
    "        corr_coeff_arr = []\n",
    "        for _ in range(n_of_resamples):\n",
    "            bootstrap_sample = rng.choice(sample, size=n)\n",
    "            # print(bootstrap_sample.shape)\n",
    "            corr_coeff = np.corrcoef(bootstrap_sample, rowvar=False)[0,1]\n",
    "            corr_coeff_arr.append(corr_coeff)\n",
    "        efron_borders.append([np.quantile(corr_coeff_arr, (1-gamma)/2),\n",
    "                              np.quantile(corr_coeff_arr, 1-(1-gamma)/2)])\n",
    "\n",
    "    left, right = zip(*efron_borders)\n",
    "    plt.plot(left)\n",
    "    plt.plot(right)\n",
    "    left = np.array(left)\n",
    "    right = np.array(right)\n",
    "    prob_left = np.sum(rho > right)/number_of_trials\n",
    "    prob_right = np.sum(rho < left)/number_of_trials\n",
    "    return prob_right, prob_left\n",
    "\n",
    "\n",
    "def calculate_correlation_matrices(a):\n",
    "    # Reshape 'a' to (m, 2, n) to perform calculations along the correct axes\n",
    "    reshaped_a = a.swapaxes(1, 2)\n",
    "\n",
    "    # Calculate correlation matrix for each subarray using vectorized operations\n",
    "    mean_a = reshaped_a.mean(axis=2, keepdims=True)\n",
    "    std_a = reshaped_a.std(axis=2, keepdims=True)\n",
    "    centered_a = reshaped_a - mean_a\n",
    "    normalized_a = centered_a / std_a\n",
    "\n",
    "    # Transpose 'normalized_a' to (m, n, 2) and reshape it back to (m, 2, n) to align dimensions\n",
    "    normalized_a = normalized_a.transpose(0, 2, 1)\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrices = np.matmul(\n",
    "        normalized_a, normalized_a.transpose(0, 2, 1)) / len(a[0])\n",
    "    corr_arr = np.array([corr_matrice[0, 1] for corr_matrice in corr_matrices])\n",
    "    return corr_arr\n",
    "\n",
    "def efron_true_proba(n, rho, gamma, number_of_trials, n_of_resamples):\n",
    "    alpha = np.sqrt(rho / (1 - rho))\n",
    "    efron_borders = []\n",
    "    for i in tqdm(range(number_of_trials)):\n",
    "        z = ss.expon.rvs(size=n)\n",
    "        x = ss.expon.rvs(size=n) + alpha * z\n",
    "        y = ss.expon.rvs(size=n) + alpha * z\n",
    "        sample = np.stack([x, y], axis=-1)\n",
    "        # print(sample.shape)\n",
    "\n",
    "        indices = np.random.randint(0, n, size=(n_of_resamples, n))\n",
    "        resamples = sample[indices]\n",
    "        # print(resamples.shape)\n",
    "        \n",
    "        corr_coeff_arr = calculate_correlation_matrices(resamples)\n",
    "        \n",
    "        \n",
    "        efron_borders.append([np.quantile(corr_coeff_arr, (1-gamma)/2), \n",
    "                              np.quantile(corr_coeff_arr, 1-(1-gamma)/2)])\n",
    "\n",
    "    left, right = zip(*efron_borders)\n",
    "    plt.plot(left)\n",
    "    plt.plot(right)\n",
    "    left = np.array(left)\n",
    "    right = np.array(right)\n",
    "    prob_left = np.sum(rho > right)/number_of_trials\n",
    "    prob_right = np.sum(rho < left)/number_of_trials\n",
    "    return prob_right, prob_left\n",
    "\n",
    "\n",
    "# print(efron_true_proba(30, 0.6, 0.95, 100, 1000))\n",
    "print(efron_true_proba_slow(30, 0.6, 0.95, 10000, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 7835.33333333  5717.33333333  2357.33333333  7478.66666667\n",
      "  3490.66666667 65690.66666667]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "invalid index to scalar variable.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 33\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m     29\u001b[0m     \u001b[38;5;66;03m# correlation = covariance / np.sqrt(var_x * var_y)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m     \u001b[38;5;66;03m# return correlation\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# calculate_correlation(b)\u001b[39;00m\n\u001b[0;32m---> 33\u001b[0m \u001b[43mcalculate_correlation\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# np.corrcoef(sample[0])\u001b[39;00m\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# a = [[1,10,100], [3, 30, 300]]\u001b[39;00m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;66;03m# np.mean(a, axis=1)\u001b[39;00m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28mprint\u001b[39m(x)\n",
      "Cell \u001b[0;32mIn[14], line 26\u001b[0m, in \u001b[0;36mcalculate_correlation\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m     24\u001b[0m var_y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mvar(y, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28mprint\u001b[39m((x \u001b[38;5;241m-\u001b[39m mean_x) \u001b[38;5;241m*\u001b[39m (y \u001b[38;5;241m-\u001b[39m mean_y))\n\u001b[0;32m---> 26\u001b[0m covariance \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean((x \u001b[38;5;241m-\u001b[39m \u001b[43mmean_x\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m) \u001b[38;5;241m*\u001b[39m (y \u001b[38;5;241m-\u001b[39m mean_y[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, \u001b[38;5;241m0\u001b[39m]), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28mprint\u001b[39m(covariance)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "\u001b[0;31mIndexError\u001b[0m: invalid index to scalar variable."
     ]
    }
   ],
   "source": [
    "rho = 0.6\n",
    "alpha = np.sqrt(rho / (1 - rho))\n",
    "n_of_resamples = 3\n",
    "n = 5\n",
    "z = ss.expon.rvs(size=(n_of_resamples, n), random_state=1)\n",
    "x = ss.expon.rvs(size=(n_of_resamples, n), random_state=1) + alpha * z\n",
    "y = ss.expon.rvs(size=(n_of_resamples, n), random_state=1) + alpha * z\n",
    "sample = np.stack([x, y], axis=-1)\n",
    "# print(sample)\n",
    "np.reshape(sample, (n_of_resamples, -1, 1))\n",
    "\n",
    "a = [[[1, 2], [10, 20], [100, 200]], [[3, 4], [30, 30], [300, 400]]]\n",
    "b = [[[1,10,100], [2, 20, 200]], [[3, 30, 300], [4, 40, 400]]]\n",
    "# a = np.reshape(a, (2, 2, -1), )\n",
    "# a\n",
    "x, y = zip(*b)\n",
    "\n",
    "def calculate_correlation(sample):\n",
    "    sample = np.reshape(sample, (-1, 2))\n",
    "    x, y = zip(*sample)\n",
    "    mean_x = np.mean(x, axis=-1)\n",
    "    mean_y = np.mean(y, axis=-1)\n",
    "    var_x = np.var(x, axis=-1)\n",
    "    var_y = np.var(y, axis=-1)\n",
    "    print((x - mean_x) * (y - mean_y))\n",
    "    covariance = np.mean((x - mean_x[..., 0]) * (y - mean_y[..., 0]), axis=-1)\n",
    "    print(covariance)\n",
    "    pass\n",
    "    # correlation = covariance / np.sqrt(var_x * var_y)\n",
    "    # return correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1. -1. -1.]\n",
      " [-1.  1.  1.]\n",
      " [-1.  1.  1.]]\n"
     ]
    }
   ],
   "source": [
    "a = [[[1, 2], [5, -3], [-3, -7]], [[3, 4], [30, 30], [300, 400]]]\n",
    "print(np.corrcoef(a[0]))\n",
    "x,y = zip(*a[0])\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.02868852,  0.24489943])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming 'a' is your array with shape (m, n, 2)\n",
    "# Create some random data for demonstration\n",
    "a = np.array([[[1, 2], [5, -3], [-3, -7]], [[3, 4], [30, 30], [300, 400]]])\n",
    "\n",
    "def calculate_correlation_matrices(a):\n",
    "    # Reshape 'a' to (m, 2, n) to perform calculations along the correct axes\n",
    "    reshaped_a = a.swapaxes(1, 2)\n",
    "\n",
    "    # Calculate correlation matrix for each subarray using vectorized operations\n",
    "    mean_a = reshaped_a.mean(axis=2, keepdims=True)\n",
    "    std_a = reshaped_a.std(axis=2, keepdims=True)\n",
    "    centered_a = reshaped_a - mean_a\n",
    "    normalized_a = centered_a / std_a\n",
    "\n",
    "    # Transpose 'normalized_a' to (m, n, 2) and reshape it back to (m, 2, n) to align dimensions\n",
    "    normalized_a = normalized_a.transpose(0, 2, 1)\n",
    "\n",
    "    # Calculate correlation matrix\n",
    "    corr_matrices = np.matmul(normalized_a, normalized_a.transpose(0, 2, 1)) / n\n",
    "    corr_arr = np.array([corr_matrice[0,1] for corr_matrice in corr_matrices])\n",
    "    return corr_arr\n",
    "\n",
    "calculate_correlation_matrices(a)\n",
    "# np.corrcoef(a[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
