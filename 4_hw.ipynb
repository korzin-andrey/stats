{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as ss\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 1 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15600\n"
     ]
    }
   ],
   "source": [
    "def sample_size(p, rel_tol) -> int:\n",
    "    n = 0\n",
    "    error = rel_tol + 1\n",
    "    while error > rel_tol:\n",
    "        n += 1\n",
    "        sigma_phi = np.sqrt((1-p)/(n*p))\n",
    "        error = sigma_phi\n",
    "    return n\n",
    "\n",
    "\n",
    "p = 0.025\n",
    "rel_tol = 0.05\n",
    "\n",
    "n = sample_size(p, rel_tol)\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 2 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4579\n"
     ]
    }
   ],
   "source": [
    "def sample_size(gamma, alpha, delta):\n",
    "    error = delta + 1\n",
    "    n = 1\n",
    "    while error >= delta:\n",
    "        z_quantile = ss.norm.ppf(1 - alpha)\n",
    "        phi_z_quantile = ss.norm.pdf(z_quantile)\n",
    "        error = (gamma/(6*np.sqrt(n)))*(2*z_quantile**2+1)*phi_z_quantile\n",
    "        n+=1\n",
    "    return n-1\n",
    "\n",
    "result = sample_size(2, 0.025, 0.025 * 0.1)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 3 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доверительный интервал для p: (0.052368745896216595, 0.36041886474075696)\n"
     ]
    }
   ],
   "source": [
    "def pivot_interval(n, k, gamma):\n",
    "    sample_mean = k/n\n",
    "    z = ss.norm.ppf((1-gamma)/2)\n",
    "    a = z**2 + n\n",
    "    b = (2*n*sample_mean + z**2)\n",
    "    c = n*sample_mean**2\n",
    "    p_R = -(-b - np.sqrt(b**2-4*a*c))/(2*a)\n",
    "    p_L = -(-b + np.sqrt(b**2-4*a*c))/(2*a)\n",
    "    return p_L, p_R\n",
    "\n",
    "\n",
    "n = 20\n",
    "k = 3\n",
    "gamma = 0.95\n",
    "\n",
    "p_alpha, p_beta = pivot_interval(n, k, gamma)\n",
    "print(\"Доверительный интервал для p:\", (p_alpha, p_beta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 4 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.09952454760270645, 509.12913485983375)\n"
     ]
    }
   ],
   "source": [
    "def var_interval(sample, gamma):\n",
    "    n = len(sample)\n",
    "    alpha = 1 - gamma\n",
    "    g_1 = ss.chi2.ppf(alpha / 2, n - 1)\n",
    "    g_2 = ss.chi2.ppf(1 - alpha / 2, n - 1)\n",
    "    sample_variance = np.var(sample, ddof=1)\n",
    "    lower_bound = (n - 1) * sample_variance / g_2\n",
    "    upper_bound = (n - 1) * sample_variance / g_1\n",
    "    return (lower_bound, upper_bound)\n",
    "\n",
    "\n",
    "print(var_interval([0, 1], 0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 5 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(-0.6051326053562245, 0.15958694402097554)\n"
     ]
    }
   ],
   "source": [
    "def loc_interval(sample, gamma, number_of_trials):\n",
    "    # MONTE-CARLO for quantiles\n",
    "    n = len(sample)\n",
    "    loc = 1\n",
    "    scale = 5\n",
    "    sample_monte_carlo = ss.cauchy(loc=loc, scale=scale).rvs((number_of_trials, n))\n",
    "    med = np.median(sample_monte_carlo, axis=1)\n",
    "    MAD = np.median(abs(sample_monte_carlo - np.resize(med, (number_of_trials, n))), axis=1)\n",
    "    g = (med - loc)/MAD\n",
    "    alpha = 1 - gamma\n",
    "    quantile_1 = np.quantile(g, alpha/2)\n",
    "    quantile_2 = np.quantile(g, 1 - alpha/2)\n",
    "    # CONFIDENCE INTERVAL\n",
    "    med_loc = np.median(sample)\n",
    "    MAD_loc = np.median(abs(sample - np.resize(med_loc, (1, n))))\n",
    "    loc_2 = med_loc - MAD_loc*quantile_1\n",
    "    loc_1 = med_loc - MAD_loc*quantile_2\n",
    "    return loc_1, loc_2\n",
    "\n",
    "\n",
    "sample = [-0.93, -1.84, -0.84, -0.13, -0.63, 0.06, -0.93, 13.29, 0.9, -2.64,\n",
    "          -0.37, 0.43, -2.41, 19.33, -0.18, 1.29, 1.32, -0.47, -0.27, 0.27,\n",
    "          1.07, -1.49, -0.78, 0.59, -0.0, -1.59, -0.28, -1.38, 0.1, 1.72]\n",
    "print(loc_interval(sample, 0.95, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 6 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.026667806686548504\n",
      "0.6366197723675814\n"
     ]
    }
   ],
   "source": [
    "from scipy.optimize import root_scalar\n",
    "def ratio(eps):\n",
    "    sigma_1 = 1\n",
    "    sigma_2 = 5\n",
    "    sigma_mean = (1-eps)*sigma_1**2 + eps*sigma_2**2\n",
    "    alpha = 0.5\n",
    "    x_alpha = 0\n",
    "    mixture_pdf = (1-eps)*(1/sigma_1/np.sqrt(2*np.pi))*np.exp(-x_alpha**2/2/sigma_1**2) + \\\n",
    "        eps*(1/sigma_2/np.sqrt(2*np.pi))*np.exp(-x_alpha**2/2/sigma_2**2)\n",
    "    sigma_median = alpha*(1-alpha)/mixture_pdf**2\n",
    "    ratio = sigma_mean/sigma_median\n",
    "    return ratio\n",
    "\n",
    "\n",
    "print(root_scalar(lambda x: ratio(x) - 1, bracket=[0, 0.5]).root)\n",
    "eps = 0\n",
    "print(ratio(eps))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 7 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4854712460301556, 0.9124958350575495]\n"
     ]
    }
   ],
   "source": [
    "def corr_interval(sample, gamma):\n",
    "    n = len(sample)\n",
    "    x, y = zip(*sample)\n",
    "    rho = np.corrcoef(x, y)[1, 0]\n",
    "    z_conf = ss.norm.ppf(1 - (1 - gamma) / 2)\n",
    "    ci_left = np.tanh(np.arctanh(rho) - z_conf/np.sqrt(n))\n",
    "    ci_right = np.tanh(np.arctanh(rho) + z_conf/np.sqrt(n))\n",
    "    return [ci_left, ci_right]\n",
    "\n",
    "\n",
    "data = np.array([(576, 3.39), (635, 3.30), (558, 2.81), (578, 3.03), (666, 3.44),\n",
    "                 (580, 3.07), (555, 3.0), (661, 3.43), (651, 3.36), (605, 3.13),\n",
    "                 (653, 3.12), (575, 2.74), (545, 2.76), (572, 2.88), (594, 2.96)])\n",
    "\n",
    "print(corr_interval(data, 0.95))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 8 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.1057, 0.0776)\n"
     ]
    }
   ],
   "source": [
    "def corr_interval(sample, gamma):\n",
    "    n = len(sample)\n",
    "    x, y = zip(*sample)\n",
    "    rho = np.corrcoef(x, y)[1, 0]\n",
    "    z_conf = ss.norm.ppf(1 - (1 - gamma) / 2)\n",
    "    ci_left = np.tanh(np.arctanh(rho) - z_conf/np.sqrt(n))\n",
    "    ci_right = np.tanh(np.arctanh(rho) + z_conf/np.sqrt(n))\n",
    "    return [ci_left, ci_right]\n",
    "\n",
    "def true_proba(n, rho, gamma, number_of_trials):\n",
    "    alpha = np.sqrt(rho / (1 - rho))\n",
    "    z = ss.expon.rvs(size=(number_of_trials, n))\n",
    "    x = ss.expon.rvs(size=(number_of_trials, n)) + alpha * z\n",
    "    y = ss.expon.rvs(size=(number_of_trials, n)) + alpha * z\n",
    "    samples = np.stack([x, y], axis=-1)\n",
    "    corr_interval_arr = [corr_interval(sample, gamma) for sample in samples]\n",
    "    left, right = zip(*corr_interval_arr)\n",
    "    left = np.array(left)\n",
    "    right = np.array(right)\n",
    "    prob_left = np.sum(rho > right)/number_of_trials\n",
    "    prob_right = np.sum(rho < left)/number_of_trials\n",
    "    return prob_right, prob_left\n",
    "\n",
    "print(true_proba(30, 0.6, 0.95, 10000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 9 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:15<00:00, 626.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.0495, 0.0389)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def efron_true_proba_slow(n, rho, gamma, number_of_trials, n_of_resamples):\n",
    "    alpha = np.sqrt(rho / (1 - rho))\n",
    "    efron_borders = []\n",
    "    rng = np.random.default_rng()\n",
    "    for i in tqdm(range(number_of_trials)):\n",
    "        z = ss.expon.rvs(size=n)\n",
    "        x = ss.expon.rvs(size=n) + alpha * z\n",
    "        y = ss.expon.rvs(size=n) + alpha * z\n",
    "        sample = np.stack([x, y], axis=-1)\n",
    "\n",
    "        corr_coeff_arr = []\n",
    "        for _ in range(n_of_resamples):\n",
    "            bootstrap_sample = rng.choice(sample, size=n)\n",
    "            # print(bootstrap_sample.shape)\n",
    "            corr_coeff = np.corrcoef(bootstrap_sample, rowvar=False)[0,1]\n",
    "            corr_coeff_arr.append(corr_coeff)\n",
    "        efron_borders.append([np.quantile(corr_coeff_arr, (1-gamma)/2),\n",
    "                              np.quantile(corr_coeff_arr, 1-(1-gamma)/2)])\n",
    "\n",
    "    left, right = zip(*efron_borders)\n",
    "    plt.plot(left)\n",
    "    plt.plot(right)\n",
    "    left = np.array(left)\n",
    "    right = np.array(right)\n",
    "    prob_left = np.sum(rho > right)/number_of_trials\n",
    "    prob_right = np.sum(rho < left)/number_of_trials\n",
    "    return prob_right, prob_left\n",
    "\n",
    "\n",
    "def calculate_correlation_coefficient(data):\n",
    "    x = data[:, :, 0]\n",
    "    y = data[:, :, 1]\n",
    "    mean_x = np.mean(x, axis=1, keepdims=True)\n",
    "    mean_y = np.mean(y, axis=1, keepdims=True)\n",
    "    x_diff = x - mean_x\n",
    "    y_diff = y - mean_y\n",
    "    cov_xx = np.sum(x_diff ** 2, axis=1) / x.shape[1]\n",
    "    cov_yy = np.sum(y_diff ** 2, axis=1) / y.shape[1]\n",
    "    cov_xy = np.sum(x_diff * y_diff, axis=1) / x.shape[1]\n",
    "\n",
    "    correlation_coefficients = cov_xy / np.sqrt(cov_xx * cov_yy)\n",
    "\n",
    "    return correlation_coefficients\n",
    "\n",
    "def efron_true_proba(n, rho, gamma, number_of_trials, n_of_resamples):\n",
    "    alpha = np.sqrt(rho / (1 - rho))\n",
    "    efron_borders = []\n",
    "    for i in tqdm(range(number_of_trials)):\n",
    "        z = ss.expon.rvs(size=n)\n",
    "        x = ss.expon.rvs(size=n) + alpha * z\n",
    "        y = ss.expon.rvs(size=n) + alpha * z\n",
    "        sample = np.stack([x, y], axis=-1)\n",
    "        # print(sample.shape)\n",
    "\n",
    "        indices = np.random.randint(0, n, size=(n_of_resamples, n))\n",
    "        resamples = sample[indices]\n",
    "\n",
    "        corr_coeff_arr = calculate_correlation_coefficient(resamples)\n",
    "        efron_borders.append([np.quantile(corr_coeff_arr, (1-gamma)/2), \n",
    "                              np.quantile(corr_coeff_arr, 1-(1-gamma)/2)])\n",
    "\n",
    "    left, right = zip(*efron_borders)\n",
    "    # plt.plot(left)\n",
    "    # plt.plot(right)\n",
    "    left = np.array(left)\n",
    "    right = np.array(right)\n",
    "    prob_left = np.sum(rho > right)/number_of_trials\n",
    "    prob_right = np.sum(rho < left)/number_of_trials\n",
    "    return prob_right, prob_left\n",
    "\n",
    "\n",
    "print(efron_true_proba(30, 0.6, 0.95, 10000, 1000))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### 10 task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10000/10000 [00:16<00:00, 598.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0.35917851334230655, 0.9845686447889187)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def calculate_correlation_coefficient(data):\n",
    "    x = data[:, :, 0]\n",
    "    y = data[:, :, 1]\n",
    "    mean_x = np.mean(x, axis=1, keepdims=True)\n",
    "    mean_y = np.mean(y, axis=1, keepdims=True)\n",
    "    x_diff = x - mean_x\n",
    "    y_diff = y - mean_y\n",
    "    cov_xx = np.sum(x_diff ** 2, axis=1) / x.shape[1]\n",
    "    cov_yy = np.sum(y_diff ** 2, axis=1) / y.shape[1]\n",
    "    cov_xy = np.sum(x_diff * y_diff, axis=1) / x.shape[1]\n",
    "\n",
    "    correlation_coefficients = cov_xy / np.sqrt(cov_xx * cov_yy)\n",
    "\n",
    "    return correlation_coefficients\n",
    "\n",
    "\n",
    "def bootstrap_t(sample, gamma, n_of_resamples, sigma_resamples):\n",
    "    alpha = 0.26\n",
    "    quantile_norm_low = ss.norm.ppf(alpha)\n",
    "    quantile_norm_high = ss.norm.ppf(1-alpha)\n",
    "    n = len(sample)\n",
    "\n",
    "    r_arr = np.array([])\n",
    "\n",
    "    corr_star = np.arctanh(np.corrcoef(sample, rowvar=False)[0, 1])\n",
    "    sigma_star = (np.quantile(sample, 1 - alpha) - np.quantile(sample, alpha)) / \\\n",
    "        (quantile_norm_high - quantile_norm_low)\n",
    "\n",
    "    for _ in tqdm(range(n_of_resamples)):\n",
    "        # bootstrap for sigma\n",
    "        indices_sigma = np.random.randint(0, n, size=(sigma_resamples, n))\n",
    "        resamples_sigma = sample[indices_sigma]\n",
    "        corr_coeff_arr = calculate_correlation_coefficient(resamples_sigma)\n",
    "        quantile_low = np.quantile(corr_coeff_arr, alpha)\n",
    "        quantile_high = np.quantile(corr_coeff_arr, 1 - alpha)\n",
    "\n",
    "        b_sample = sample[np.random.randint(0, n, size=n)]\n",
    "        sigma_b = (quantile_high-quantile_low) / \\\n",
    "            (quantile_norm_high-quantile_norm_low)\n",
    "        corr_b = np.corrcoef(b_sample, rowvar=False)[0, 1]\n",
    "        r_b = (np.arctanh(corr_b) - corr_star)/sigma_b\n",
    "        r_arr = np.append(r_arr, r_b)\n",
    "\n",
    "    t_quantile_low = np.quantile(r_arr, (1-gamma)/2)\n",
    "    t_quantile_high = np.quantile(r_arr, 1 - (1-gamma/2))\n",
    "\n",
    "    conf_int_low = np.tanh(corr_star - t_quantile_high*sigma_star)\n",
    "    conf_int_high = np.tanh(corr_star - t_quantile_low*sigma_star)\n",
    "    return conf_int_low, conf_int_high\n",
    "\n",
    "\n",
    "\n",
    "n, rho = 30, 0.6\n",
    "alpha = np.sqrt(rho / (1 - rho))\n",
    "z = ss.expon.rvs(size=n, random_state=10)\n",
    "x = ss.expon.rvs(size=n, random_state=20) + alpha * z\n",
    "y = ss.expon.rvs(size=n, random_state=30) + alpha * z\n",
    "sample = np.stack([x, y], axis=-1)\n",
    "\n",
    "\n",
    "print(bootstrap_t(sample, 0.95, 10000, 1000))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
